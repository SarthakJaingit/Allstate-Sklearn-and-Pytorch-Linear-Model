{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.preprocessing import PolynomialFeatures \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport torch.nn as nn\nfrom torch import optim \nimport torch\nimport torch.utils.data as Data\nfrom sklearn.ensemble import AdaBoostRegressor","execution_count":91,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/allstate-claims-severity/train.csv\")\nprint(train_df.shape)\ntrain_df.head()","execution_count":67,"outputs":[{"output_type":"stream","text":"(188318, 132)\n","name":"stdout"},{"output_type":"execute_result","execution_count":67,"data":{"text/plain":"   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont6     cont7  \\\n0   1    A    B    A    B    A    A    A    A    B  ...  0.718367  0.335060   \n1   2    A    B    A    A    A    A    A    A    B  ...  0.438917  0.436585   \n2   5    A    B    A    A    B    A    A    A    B  ...  0.289648  0.315545   \n3  10    B    B    A    B    A    A    A    A    B  ...  0.440945  0.391128   \n4  11    A    B    A    B    A    A    A    A    B  ...  0.178193  0.247408   \n\n     cont8    cont9   cont10    cont11    cont12    cont13    cont14     loss  \n0  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493  0.714843  2213.18  \n1  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431  0.304496  1283.60  \n2  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709  0.774425  3005.09  \n3  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077  0.602642   939.85  \n4  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011  0.432606  2763.85  \n\n[5 rows x 132 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>cat9</th>\n      <th>...</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>cont14</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>...</td>\n      <td>0.718367</td>\n      <td>0.335060</td>\n      <td>0.30260</td>\n      <td>0.67135</td>\n      <td>0.83510</td>\n      <td>0.569745</td>\n      <td>0.594646</td>\n      <td>0.822493</td>\n      <td>0.714843</td>\n      <td>2213.18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>...</td>\n      <td>0.438917</td>\n      <td>0.436585</td>\n      <td>0.60087</td>\n      <td>0.35127</td>\n      <td>0.43919</td>\n      <td>0.338312</td>\n      <td>0.366307</td>\n      <td>0.611431</td>\n      <td>0.304496</td>\n      <td>1283.60</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>...</td>\n      <td>0.289648</td>\n      <td>0.315545</td>\n      <td>0.27320</td>\n      <td>0.26076</td>\n      <td>0.32446</td>\n      <td>0.381398</td>\n      <td>0.373424</td>\n      <td>0.195709</td>\n      <td>0.774425</td>\n      <td>3005.09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>...</td>\n      <td>0.440945</td>\n      <td>0.391128</td>\n      <td>0.31796</td>\n      <td>0.32128</td>\n      <td>0.44467</td>\n      <td>0.327915</td>\n      <td>0.321570</td>\n      <td>0.605077</td>\n      <td>0.602642</td>\n      <td>939.85</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>...</td>\n      <td>0.178193</td>\n      <td>0.247408</td>\n      <td>0.24564</td>\n      <td>0.22089</td>\n      <td>0.21230</td>\n      <td>0.204687</td>\n      <td>0.202213</td>\n      <td>0.246011</td>\n      <td>0.432606</td>\n      <td>2763.85</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 132 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = train_df[\"loss\"]\nfeatures = train_df.drop(\"loss\", axis = 1)\nprint(loss.shape)\nprint(features.shape)","execution_count":68,"outputs":[{"output_type":"stream","text":"(188318,)\n(188318, 131)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Check for Skewness in the data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Look at cont variables\nfeatures.describe()","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"                  id          cont1          cont2          cont3  \\\ncount  188318.000000  188318.000000  188318.000000  188318.000000   \nmean   294135.982561       0.493861       0.507188       0.498918   \nstd    169336.084867       0.187640       0.207202       0.202105   \nmin         1.000000       0.000016       0.001149       0.002634   \n25%    147748.250000       0.346090       0.358319       0.336963   \n50%    294539.500000       0.475784       0.555782       0.527991   \n75%    440680.500000       0.623912       0.681761       0.634224   \nmax    587633.000000       0.984975       0.862654       0.944251   \n\n               cont4          cont5          cont6          cont7  \\\ncount  188318.000000  188318.000000  188318.000000  188318.000000   \nmean        0.491812       0.487428       0.490945       0.484970   \nstd         0.211292       0.209027       0.205273       0.178450   \nmin         0.176921       0.281143       0.012683       0.069503   \n25%         0.327354       0.281143       0.336105       0.350175   \n50%         0.452887       0.422268       0.440945       0.438285   \n75%         0.652072       0.643315       0.655021       0.591045   \nmax         0.954297       0.983674       0.997162       1.000000   \n\n               cont8          cont9         cont10         cont11  \\\ncount  188318.000000  188318.000000  188318.000000  188318.000000   \nmean        0.486437       0.485506       0.498066       0.493511   \nstd         0.199370       0.181660       0.185877       0.209737   \nmin         0.236880       0.000080       0.000000       0.035321   \n25%         0.312800       0.358970       0.364580       0.310961   \n50%         0.441060       0.441450       0.461190       0.457203   \n75%         0.623580       0.566820       0.614590       0.678924   \nmax         0.980200       0.995400       0.994980       0.998742   \n\n              cont12         cont13         cont14  \ncount  188318.000000  188318.000000  188318.000000  \nmean        0.493150       0.493138       0.495717  \nstd         0.209427       0.212777       0.222488  \nmin         0.036232       0.000228       0.179722  \n25%         0.311661       0.315758       0.294610  \n50%         0.462286       0.363547       0.407403  \n75%         0.675759       0.689974       0.724623  \nmax         0.998484       0.988494       0.844848  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cont1</th>\n      <th>cont2</th>\n      <th>cont3</th>\n      <th>cont4</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>cont14</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n      <td>188318.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>294135.982561</td>\n      <td>0.493861</td>\n      <td>0.507188</td>\n      <td>0.498918</td>\n      <td>0.491812</td>\n      <td>0.487428</td>\n      <td>0.490945</td>\n      <td>0.484970</td>\n      <td>0.486437</td>\n      <td>0.485506</td>\n      <td>0.498066</td>\n      <td>0.493511</td>\n      <td>0.493150</td>\n      <td>0.493138</td>\n      <td>0.495717</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>169336.084867</td>\n      <td>0.187640</td>\n      <td>0.207202</td>\n      <td>0.202105</td>\n      <td>0.211292</td>\n      <td>0.209027</td>\n      <td>0.205273</td>\n      <td>0.178450</td>\n      <td>0.199370</td>\n      <td>0.181660</td>\n      <td>0.185877</td>\n      <td>0.209737</td>\n      <td>0.209427</td>\n      <td>0.212777</td>\n      <td>0.222488</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000016</td>\n      <td>0.001149</td>\n      <td>0.002634</td>\n      <td>0.176921</td>\n      <td>0.281143</td>\n      <td>0.012683</td>\n      <td>0.069503</td>\n      <td>0.236880</td>\n      <td>0.000080</td>\n      <td>0.000000</td>\n      <td>0.035321</td>\n      <td>0.036232</td>\n      <td>0.000228</td>\n      <td>0.179722</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>147748.250000</td>\n      <td>0.346090</td>\n      <td>0.358319</td>\n      <td>0.336963</td>\n      <td>0.327354</td>\n      <td>0.281143</td>\n      <td>0.336105</td>\n      <td>0.350175</td>\n      <td>0.312800</td>\n      <td>0.358970</td>\n      <td>0.364580</td>\n      <td>0.310961</td>\n      <td>0.311661</td>\n      <td>0.315758</td>\n      <td>0.294610</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>294539.500000</td>\n      <td>0.475784</td>\n      <td>0.555782</td>\n      <td>0.527991</td>\n      <td>0.452887</td>\n      <td>0.422268</td>\n      <td>0.440945</td>\n      <td>0.438285</td>\n      <td>0.441060</td>\n      <td>0.441450</td>\n      <td>0.461190</td>\n      <td>0.457203</td>\n      <td>0.462286</td>\n      <td>0.363547</td>\n      <td>0.407403</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>440680.500000</td>\n      <td>0.623912</td>\n      <td>0.681761</td>\n      <td>0.634224</td>\n      <td>0.652072</td>\n      <td>0.643315</td>\n      <td>0.655021</td>\n      <td>0.591045</td>\n      <td>0.623580</td>\n      <td>0.566820</td>\n      <td>0.614590</td>\n      <td>0.678924</td>\n      <td>0.675759</td>\n      <td>0.689974</td>\n      <td>0.724623</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>587633.000000</td>\n      <td>0.984975</td>\n      <td>0.862654</td>\n      <td>0.944251</td>\n      <td>0.954297</td>\n      <td>0.983674</td>\n      <td>0.997162</td>\n      <td>1.000000</td>\n      <td>0.980200</td>\n      <td>0.995400</td>\n      <td>0.994980</td>\n      <td>0.998742</td>\n      <td>0.998484</td>\n      <td>0.988494</td>\n      <td>0.844848</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Only one variable is over 1 skewness which is pretty good. Feature Data does not need skewness\ncont_skewness_dict = dict()\nfor columns in features.columns:\n    if columns[:4] == \"cont\":\n        column_skewness = eval('features[\"{}\"].skew()'.format(columns))\n        cont_skewness_dict[columns] = column_skewness\nprint(cont_skewness_dict)\nfor value in cont_skewness_dict:\n    if cont_skewness_dict[value] > 1 or cont_skewness_dict[value] < -1:\n        print(\"Data skewness over at one at\", str(value))\n        break\n\n#Loss needs to be logged\nprint(loss.skew())","execution_count":70,"outputs":[{"output_type":"stream","text":"{'cont1': 0.5164240212162501, 'cont2': -0.3109412513683013, 'cont3': -0.010002283912088425, 'cont4': 0.41609602949567703, 'cont5': 0.6816224364137877, 'cont6': 0.4612142679626868, 'cont7': 0.8260528331279865, 'cont8': 0.6766340713246528, 'cont9': 1.0724287198115823, 'cont10': 0.35500094742512944, 'cont11': 0.28082142843754204, 'cont12': 0.29199208040362884, 'cont13': 0.38074220048057467, 'cont14': 0.24867408719289721}\nData skewness over at one at cont9\n3.7949583775378604\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets remove outliers in loss\naverage_loss = np.mean((loss))\nmaximum_loss = np.max((loss))\nprint(\"Average_loss {}\".format(average_loss))\nprint(\"Maximum_loss {}\".format(maximum_loss))\n\n","execution_count":71,"outputs":[{"output_type":"stream","text":"Average_loss 3037.3376856699792\nMaximum_loss 121012.25\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_train = pd.get_dummies(features)\nloss_train = np.log(loss)\n\nX_train, X_test, y_train, y_test = train_test_split(features_train, loss_train, test_size = 0.33)\n\n#Lets run a baseline model\nlinear_regression = LinearRegression()\nlinear_regression.fit(X_train, y_train)\nbase_predictions = linear_regression.predict(X_test)\n\n\nprint(\"Mean squared error {}\".format(mean_squared_error(np.exp(y_test), np.exp(base_predictions))))\nprint(\"Mean absolute error {}\".format(mean_absolute_error(np.exp(y_test), np.exp(base_predictions))))\n\n","execution_count":72,"outputs":[{"output_type":"stream","text":"Mean squared error 4990952.6796163805\nMean absolute error 1249.7197229205242\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_train = np.log(loss)","execution_count":73,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Here we are going to use PCA or Principal Component Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets get the columns for cont variables and category variables \nskimmed_features = features.drop(\"id\", axis = 1)\ncategory_features = skimmed_features.iloc[:, :116]\ncont_features = skimmed_features.iloc[:, 116:]","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(category_features.shape)\nprint(cont_features.shape)","execution_count":75,"outputs":[{"output_type":"stream","text":"(188318, 116)\n(188318, 14)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components = 9)\ncont_reduced = pca.fit_transform(cont_features)\nprint(cont_reduced.shape)\n\ncont_explained = 0\nfor value in pca.explained_variance_ratio_:\n    cont_explained += value\ncont_explained\n    ","execution_count":76,"outputs":[{"output_type":"stream","text":"(188318, 9)\n","name":"stdout"},{"output_type":"execute_result","execution_count":76,"data":{"text/plain":"0.9697930991790539"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sparse_category_features = pd.get_dummies(category_features)\nsparse_category_features.shape","execution_count":77,"outputs":[{"output_type":"execute_result","execution_count":77,"data":{"text/plain":"(188318, 1139)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components = 150)\ncat_reduced = pca.fit_transform(sparse_category_features)\nprint(cat_reduced.shape)\n\ncat_explained = 0\nfor value in pca.explained_variance_ratio_:\n    cat_explained += value\ncat_explained","execution_count":78,"outputs":[{"output_type":"stream","text":"(188318, 150)\n","name":"stdout"},{"output_type":"execute_result","execution_count":78,"data":{"text/plain":"0.9166537727534473"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now we are going to combine the data into one dataframe.\nreduced_feature = np.hstack((cat_reduced,cont_reduced))\nprint(\"Reduced PCA Dataset: {}\".format(reduced_feature.shape))","execution_count":79,"outputs":[{"output_type":"stream","text":"Reduced PCA Dataset: (188318, 159)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Now we are going to try to run some supervised Models on the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(reduced_feature))\nprint(\"Did not use fit_transform with PCA\")\nprint(type(loss_train))","execution_count":80,"outputs":[{"output_type":"stream","text":"<class 'numpy.ndarray'>\nDid not use fit_transform with PCA\n<class 'pandas.core.series.Series'>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(reduced_feature, loss_train, test_size = 0.33)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":81,"outputs":[{"output_type":"stream","text":"(126173, 159)\n(126173,)\n(62145, 159)\n(62145,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_scores(pred, y_true):\n    print(\"The Means absolute error: {}\".format(mean_absolute_error(np.exp(y_true), np.exp(pred))))\n    print(\"The Mean Squared error: {}\".format(mean_squared_error(np.exp(y_true), np.exp(pred))))","execution_count":82,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(X_train))\nprint(type(y_train))","execution_count":83,"outputs":[{"output_type":"stream","text":"<class 'numpy.ndarray'>\n<class 'pandas.core.series.Series'>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets run a polynomial regression\n\n# polynomial_object = PolynomialFeatures(2)\n# poly_data = polynomial_object.fit_transform(X_train)\n\n# linear_regression = LinearRegression()\n# linear_regression.fit(X_train, y_train)\n# polynomial_pred = linear_regression.predict(X_test)\n\n# find_scores(polynomial_pred, y_test)\n#Uncomment to use Polynomial Regression. Note: Takes a lot of RAM. ","execution_count":84,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision Tree Regressor Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now lets run a Decision Tree Regressor except now we will use GridSearchCV to validate the best model\nparameters = {\"max_depth\": [5, 10]}\ntree_scoring = make_scorer(mean_squared_error)\ntree_regressor = DecisionTreeRegressor()\ngrid = GridSearchCV(tree_regressor, parameters, scoring = tree_scoring)\ngrid_fit = grid.fit(X_train, y_train)\nbest_tree = grid_fit.best_estimator_\nprint(\"Best estimator: {}\".format(best_tree))\n\nbest_tree_fit = best_tree.fit(X_train, y_train)\ntree_predictions = best_tree_fit.predict(X_test)\n\nfind_scores(tree_predictions, y_test)","execution_count":85,"outputs":[{"output_type":"stream","text":"Best estimator: DecisionTreeRegressor(max_depth=5)\nThe Means absolute error: 1423.8180418369036\nThe Mean Squared error: 6033486.5566932885\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Model (Bagging Model)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# parameters = {\"n_estimators\": [5, 10]}\n# random_forest = RandomForestRegressor(max_depth = 5)\n# grid = GridSearchCV(random_forest, parameters, scoring = absolute_scoring)\n# grid_fit = grid.fit(X_train, y_train)\n# best_forest = grid_fit.best_estimator_\n# print(\"Best random Forest{}\".format(best_forest))\n# print(\"The run time{}\".format(grid_fit.refit_time_))\n\n# best_forest_fit = best_forest.fit(X_train, y_train)\n# forest_predictions = best_forest_fit.predict(X_test)\n\nrandom_forest = RandomForestRegressor(n_estimators = 10, max_depth = 5)\nrandom_forest_fit = random_forest.fit(X_train, y_train)\nforest_predictions = random_forest_fit.predict(X_test)\n\nfind_scores(forest_predictions, y_test)","execution_count":86,"outputs":[{"output_type":"stream","text":"The Means absolute error: 1393.0462689440915\nThe Mean Squared error: 5888803.927847286\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Lasso Model (Regularized Linear Regression)"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\"alpha\": [0.5, 1, 2, 5]}\nabsolute_scoring = make_scorer(mean_absolute_error)\nlasso_model = Lasso()\ngrid = GridSearchCV(lasso_model, parameters, scoring = absolute_scoring)\ngrid_fit = grid.fit(X_train, y_train)\nbest_lasso = grid_fit.best_estimator_\nprint(\"Best Lasso Model L1 Regularization: {}\".format(best_lasso))\nprint(\"The run time: {}\".format(grid_fit.refit_time_))\n\nbest_lasso_fit = best_lasso.fit(X_train, y_train)\nlasso_predictions = best_lasso_fit.predict(X_test)\n\nfind_scores(lasso_predictions, y_test)","execution_count":88,"outputs":[{"output_type":"stream","text":"Best Lasso Model L1 Regularization: Lasso(alpha=0.5)\nThe run time: 0.2651042938232422\nThe Means absolute error: 1800.2204337642486\nThe Mean Squared error: 9333794.605318602\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":89,"outputs":[{"output_type":"execute_result","execution_count":89,"data":{"text/plain":"(126173, 159)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## AdaBoostRegressor Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_boost = AdaBoostRegressor(n_estimators = 10, learning_rate = 0.5)\nada_boost_fit = ada_boost.fit(X_train, y_train)\nada_boost_predictions = ada_boost.predict(X_test)\n\nfind_scores(ada_boost_predictions, y_test)","execution_count":92,"outputs":[{"output_type":"stream","text":"The Means absolute error: 1493.484300079309\nThe Mean Squared error: 6822108.09384632\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Linear Neural Network Pytorch"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    \n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.fc1 = nn.Linear(159, 30)\n        self.fc2 = nn.Linear(30, 1)\n        \n        self.tanh = nn.Tanh()\n        \n        \n    def forward(self, x):\n        \n        #x shape (1, 159)\n        x = self.tanh(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x\n        \n    ","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net()\noptimizer = optim.Adam(net.parameters(), lr = 0.01)\ncriterion = nn.MSELoss()\nfor epoch in range(151):\n    \n    epoch_loss = 0\n    \n    optimizer.zero_grad()\n    X_train = torch.FloatTensor(X_train)\n    y_train = (torch.FloatTensor(y_train)).view(-1, 1)\n    output = net(X_train)\n    loss = criterion(output, y_train)\n    loss.backward()\n    optimizer.step()\n    epoch_loss += loss.item()\n    \n    if epoch % 10 == 0:\n        \n        print(\"Epoch: {}\".format(epoch))\n        print(\"Loss: {:.3f}\".format(np.exp(epoch_loss)))\n    ","execution_count":94,"outputs":[{"output_type":"stream","text":"Epoch: 0\nLoss: 9855272550329797417369600.000\nEpoch: 10\nLoss: 2819477742692118036480.000\nEpoch: 20\nLoss: 2004717669562569.250\nEpoch: 30\nLoss: 20682669.206\nEpoch: 40\nLoss: 33.357\nEpoch: 50\nLoss: 1.693\nEpoch: 60\nLoss: 2.015\nEpoch: 70\nLoss: 1.672\nEpoch: 80\nLoss: 1.555\nEpoch: 90\nLoss: 1.480\nEpoch: 100\nLoss: 1.452\nEpoch: 110\nLoss: 1.432\nEpoch: 120\nLoss: 1.417\nEpoch: 130\nLoss: 1.406\nEpoch: 140\nLoss: 1.398\nEpoch: 150\nLoss: 1.391\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = torch.FloatTensor(X_test)\ny_test = (torch.Tensor(y_test.values)).view(-1, 1)\ntest_output = net(X_test)\nloss = criterion(test_output, y_test)\nprint(\"Loss: {}\".format(torch.exp(loss)))","execution_count":95,"outputs":[{"output_type":"stream","text":"Loss: 1.427153468132019\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test[0:10])","execution_count":96,"outputs":[{"output_type":"stream","text":"tensor([[8.3665],\n        [8.5858],\n        [7.6625],\n        [6.6366],\n        [7.3773],\n        [7.7619],\n        [8.5707],\n        [8.0258],\n        [7.5327],\n        [6.8029]])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"net(X_test[0:10])","execution_count":97,"outputs":[{"output_type":"execute_result","execution_count":97,"data":{"text/plain":"tensor([[8.2666],\n        [8.5761],\n        [7.9743],\n        [6.7963],\n        [6.7228],\n        [7.6892],\n        [8.5619],\n        [8.4828],\n        [7.3714],\n        [7.2460]], grad_fn=<AddmmBackward>)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## How would you batch data\n\npandas series --> numpy_array --> torch tensor\n\n``` for (batch_i), images, labels in enumerate(loader): ```"},{"metadata":{"trusted":true},"cell_type":"code","source":"torch_dataset = Data.TensorDataset(X_train, y_train)\n\nloader = Data.DataLoader(\n    dataset=torch_dataset, \n    batch_size=32)","execution_count":98,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iterator = iter(loader)\ndata, label = iterator.next()","execution_count":99,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data)\nprint(data.shape)","execution_count":100,"outputs":[{"output_type":"stream","text":"tensor([[ 9.0991e-03, -1.0198e+00,  2.0920e+00,  ..., -5.8618e-02,\n         -1.0392e-01,  2.1025e-01],\n        [-2.4088e+00,  4.2594e-01,  1.8614e+00,  ...,  7.7747e-02,\n         -1.0327e-01,  1.3554e-02],\n        [ 2.5770e+00,  1.2572e+00, -3.8530e-01,  ...,  1.0183e-01,\n         -1.7675e-03,  1.6873e-01],\n        ...,\n        [-6.6574e-01, -1.7135e+00, -3.8765e-01,  ...,  7.0681e-02,\n          2.6254e-01,  1.0193e-01],\n        [-2.7694e+00, -5.5856e-01,  2.7902e-02,  ..., -5.1199e-02,\n         -3.7130e-01,  1.7464e-01],\n        [ 8.8886e-01, -1.8188e+00,  1.7996e+00,  ...,  1.7245e-01,\n         -6.7208e-02,  7.4193e-02]])\ntorch.Size([32, 159])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(label)\nprint(label.shape)","execution_count":101,"outputs":[{"output_type":"stream","text":"tensor([[7.7498],\n        [8.2134],\n        [9.7236],\n        [7.8824],\n        [8.7793],\n        [8.8634],\n        [7.9271],\n        [8.7014],\n        [7.7014],\n        [8.2393],\n        [7.0449],\n        [6.1065],\n        [7.3090],\n        [8.0274],\n        [7.5626],\n        [7.1166],\n        [8.4187],\n        [7.7164],\n        [8.3868],\n        [7.3674],\n        [8.5139],\n        [7.0270],\n        [8.8776],\n        [8.8213],\n        [6.8677],\n        [7.9324],\n        [7.0636],\n        [8.1018],\n        [7.4904],\n        [7.8749],\n        [8.1581],\n        [7.8240]])\ntorch.Size([32, 1])\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}